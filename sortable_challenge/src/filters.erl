-module(filters).
-compile(export_all).
-include("challenge.hrl").

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This file contains filter functions that are used to filter and sanitize the raw JSON data into things
% that can be used by the program.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% number of title token to keep
-define(TITLE_TOKENS,6).

%%%%%%%%%%%%%%%% THESE CAN BE ADJUSTED TO TUNE THE MATCHING SYSTEM %%%%%%%%%%%%%%%%%%%%%%%%%
% words in this list will be used to remove words from the tokenized family name
sanitize_family_dropnames() ->
	["digital"].

% words in this list will be marked as "optional tokens" in the tokenized model name
sanitize_model_optional_names() ->
	["digital","zoom","clik!","wide","kiss","mini","mju","tough","pen","sport"].

% words in this list will be marked as "optional tokens" only if they appear as the last token in the tokenized model name
sanitize_model_optional_last_tokens() ->
	["hs","is"].

% this allows the user to manually reassign certain model names
% form is [{product_tuple,model_priority_list}, ...]
% where product_tuple = {"manufacturer","family","modelstring"}
% and model_priority_list = [{required,"modeltoken1"},{optional,"modeltoken2"},{required,"modeltoken3"}, ...]
% note that manufacturer, family, and modelstring are strings that appear in quotes and correspond to the
% names that appear in the debug.txt file when debugging output is enabled
manual_model_priority_assignment() ->
	[
	 {{"canon","elph","300hs"},[{required,"300"},{required,"hs"}]},
	 {{"canon","elph","500hs"},[{required,"500"},{required,"hs"}]}
	].
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% manually tweak certain model priorities
% NOTE that Manufacturer, Family, and Model are after they have passed through the sanitizing functions
manual_model_priority_adjustment(Manufacturer, Family, ModelPriority) ->
	% strip out the model priorities and flatten it
	NewManufacturer = manufacturer_tokens_to_text(Manufacturer),
	NewFamily = family_tokens_to_text(Family),
	NewModel = model_tokens_to_text(ModelPriority),
	case lists:keyfind({NewManufacturer,NewFamily,NewModel},1,manual_model_priority_assignment()) of
		{_ProductTuple, ManualModelPriority} -> ManualModelPriority;
		false -> ModelPriority
	end.

% sanitize the manufacturer string and return a list of tokens
sanitize_manufacturer(Manufacturer) ->
	% tokenize manufacturer name with "-" and " " characters
  	% convert token string to lower case
	[string:to_lower(Token) || Token <- string:tokens(Manufacturer,"- ")].

% Take in a family name string, filter it, and turn it into a list of tokens
sanitize_family("") -> "";
sanitize_family(Family) ->
	% tokenize family name with " "
	% convert token string to lower case and keep only alphanumeric characters
	NewTokens1 = [ascii_filter(string:to_lower(Token)) || Token <- string:tokens(Family," ")],
	% eliminate the items in NewTokens1 that match items in the list generated by sanitize_family_dropnames
	eliminate_matches(NewTokens1, sanitize_family_dropnames()).

% prioritize tokens in the model name into "required" and "optional" tokens based on the items
% returned by sanitize_model_optional_names()
% required tokens must be present for a model in a product listing to match one of the desired products
% optional tokens help to narrow-down the match and remove ambiguities, but are not required
sanitize_model_prioritize(Token) ->
	case lists:member(Token,sanitize_model_optional_names()) of
		true -> {optional, Token};
		false -> {required, Token}
	end.

% same as above, but only for the final token
sanitize_model_reprioritize_last_prioritized_token({Priority, Token}) ->
	case lists:member(Token,sanitize_model_optional_last_tokens()) of
		true -> {optional, Token};
		false -> {Priority, Token}
	end.

% reprioritize the last token in a list of prioritized tokens
reprioritize_last_token(PrioritizedTokens) ->
	reprioritize_last_token_helper(PrioritizedTokens,[]).

% recursive helper function for reprioritize_last_token
% this should only happen if PrioritizedTokens =:= [] to start out with
reprioritize_last_token_helper([],[]) -> [];
% when we get to the last prioritized token, reprioritize it and add it to the list and return the list
reprioritize_last_token_helper([LastPrioritizedToken|[]],Acc) ->
	Acc ++ [sanitize_model_reprioritize_last_prioritized_token(LastPrioritizedToken)];
% when we're not at the last prioritized token, just add the head prioritized token onto the accumulator
reprioritize_last_token_helper([HeadPrioritizedToken|TailPrioritizedtokens],Acc) ->
	reprioritize_last_token_helper(TailPrioritizedtokens,Acc ++ [HeadPrioritizedToken]).

% convert Manufacturer tokens into a string representation.
manufacturer_tokens_to_text(ManufacturerTokens) ->
	hd(ManufacturerTokens).

% convert Family tokens into a string representation
family_tokens_to_text(FamilyTokens) ->
	case FamilyTokens of
		[_] -> hd(FamilyTokens);
		_ -> "none"
	end.

% convert models tokens into a string representation.
model_tokens_to_text(ModelTokens) ->
	lists:foldl(fun({_,Token},Acc) -> Acc ++ Token end, [], ModelTokens).

% sanitize and convert a model string into a list of tokens
sanitize_model(Model) ->
	% tokenize model name with " " and "-"
	% convert token string to lower case and keep only alphanumeric characters
	NewTokens1 = [ascii_filter(string:to_lower(Token)) || Token <- string:tokens(Model,"- ")],
	% split up tokens based on number/character transitions
	NewTokens2 = lists:foldl(fun(Token,Acc) -> Acc ++ alphanum_splitter(Token) end, [], NewTokens1),
	NewTokens3 = lists:map(fun sanitize_model_prioritize/1, NewTokens2),
	NewTokens4 = reprioritize_last_token(NewTokens3),
	NewTokens4.

% this function splits a Token into sub-tokens based on letter-number transitions
% eg: ["abc123def"] -> ["abc","123","def"]
alphanum_splitter(Token) ->
	alphanum_splitter_helper(Token, none, "", []).

% recursive helper function that actually does all the work
% when there are no other characters in the token to parse this matches
alphanum_splitter_helper([], _StringAccClass, StringAcc, ListAcc) -> ListAcc ++ [StringAcc];
% this matches for the first character being processed, and kicks off whether we are tracking a
% letter or number sub-token
alphanum_splitter_helper([HeadChar|StringTail], none, "", []) ->
	alphanum_splitter_helper(StringTail, character_class(HeadChar), [HeadChar], []);
% this matches all the other characters.
% StringAccClass tells us whether the current sub-token accumulator is a letter or number class
% if the current character is in the same class, it gets added to the StringAcc accumulator
% if it's different, StringAcc gets pushed into the list of sub-tokens, and the new character
% starts a new StringAcc
alphanum_splitter_helper([HeadChar|StringTail], StringAccClass, StringAcc, ListAcc) ->
	case character_class(HeadChar) of
		% if the head character is in the same class as the StringAccClass, then add it to the StringAcc
		Class when Class =:= StringAccClass ->
			alphanum_splitter_helper(StringTail, Class, StringAcc ++ [HeadChar], ListAcc);
		% otherwise, add the current StringAcc to ListAcc, then start a new StringAcc with the character
		Class ->
			alphanum_splitter_helper(StringTail, Class, [HeadChar], ListAcc ++ [StringAcc])
	end.

% this classifies characters into numbers, letters, or other based on their ASCII value
character_class(X) ->
	   % numbers
	if ( (X >= 48) and (X =< 57) ) ->
		   number;
	   % period
	   ( X =:= 46 ) ->
		   number;
	   % upper case letters
	   ( (X >= 65) and (X =< 90) ) ->
		   letter;
	   % lower case letters
	   ( (X >= 97) and (X =< 122) ) ->
		   letter;
	   % everything else
	   true ->
		   other
	end.

% sanitize the title string into tokens
% Note that is the vast majority of product titles, the manufacturer, model, and family are mentioned within the
% first few words.  Thus we keep only the first ?TITLE_TOKENS number of tokens. 
sanitize_title(Title) ->
	% tokenize title with "-" , "," and " " and convert to lower case
	TokensTemp = [ascii_filter(string:to_lower(Token)) || Token <- string:tokens(Title,"- ,")],
	% keep only the first ?TITLE_TOKENS number of tokens
	Tokens1 = lists:sublist(TokensTemp, ?TITLE_TOKENS),
	% split these up based on number/letter transitions
	lists:foldl(fun(Token,Acc) -> Acc ++ alphanum_splitter(Token) end, [], Tokens1).

% keep only alphanumeric characters (including period) in a string
ascii_filter(String) ->
	% an anonymous function that returns true when a character matches
	ASCII_Filter = fun
		%           numbers                         upper case letters              lower case letters             period
		(X) when ( (X >= 48) and (X =< 57) ) or ( (X >= 65 ) and (X =< 90) ) or ( (X >= 97) and (X =< 122) ) or (X =:= 46) -> true;
	    (_) -> false
	end,
	lists:filter(ASCII_Filter, String).

% filter the InputList and return only those items that do not appear in the MatchList
eliminate_matches(InputList, MatchList) ->
	% return true if InputItem does not appear in MatchList
	FilterHelper = fun(InputItem) ->
    	not lists:member(InputItem, MatchList)
    end,
	% filter out all items from InputList that appear in the MatchList
	lists:filter(FilterHelper, InputList).
